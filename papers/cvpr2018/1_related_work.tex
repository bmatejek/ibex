\section{Related Work}

Significant research in connectomics has focused on extracting information from the pixel data of the raw electron microscopy (EM) images. Building off previous work in computer vision that used normalized cuts and other graph partitioning algoirithms on images \cite{kappes2016higher,shi2000normalized,tatiraju2008image}, some of the methods apply computationally expensive graph partitioning techniques on the per-voxel images \cite{andres2012globally}. Other approaches at the per-pixel level have focused on training 2-D convolutional networks to predict membrane probabilities \cite{ciresan2012deep}. More recent work has expanded on these early networks by adding the $z$-dimension to create 3-D networks \cite{lee2015recursive}. Oftentimes these networks now predict affinities between voxels rather than membrane probabilities \cite{ronneberger2015u}. Extensive research has focused on enhancing the loss functions and optimizers for these networks \cite{chatfield2014return,maas2013rectifier,nesterov1983method}.

ADD SECTION ON CORRECTING SPLIT ERRORS

These neural networks produce probabilities that neighboring voxels belong to the same neuron. Many algorithms build on top of these affinities by agglomerating voxels to produce reconstructed label volumes of the EM images \cite{seymour2016rhoananet,nunez2014graph,parag2017anisotropic} (CITE NEUROPROOF, ZWATERSHED). Despite the successes of these algorithms they often make early local mistakes leading to errors in the segmentation. Proofreading methods create a "human-in-the-loop" framework that allows users to find errors and correct them \cite{haehn2017scalable,haehn2017guided,haehn2014design}. Flood-filling networks merge these two steps by training an end-to-end network that takes as input raw image data and produces a segmentation \cite{januszewski2016flood}. Although these networks have produced impressed segmentation accuracies, they are currently too slow for large scale connectomics reconstructions. 

The fields of computer graphics, mathematics, and biomedical visualization have produced extensive research into the skeletonization of 3D binary volumes. A large amount of research has explored topologically consistent thinning algorithms and potential medical applications of these methods \cite{palagyi20003d,palagyi2001sequential}. In computer graphics, fast medial axis algorithms allow animators to quickly move characters through successive frames \cite{baran2007automatic,bharaj2012automatically}. The Tree-structure Extraction Algorithm for Accurate and Robust Skeletons (TEASER) has been used by connectomics researchers to parameterize 3-D shapes \cite{sato2000teasar,zhao2014automatic}. 

ADD SECTION ON LEARNED SHAPE FEATURES

ADD SECTION ON GRAPH PARTITIONING